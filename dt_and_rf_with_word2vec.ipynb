{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from gensim.utils import simple_preprocess\n",
    "from gensim.models import KeyedVectors\n",
    "import numpy as np\n",
    "from experiment_baseplate import load_split_data\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading Glove Model\n",
      "1193514 words loaded!\n"
     ]
    }
   ],
   "source": [
    "# Prepare Embeddings\n",
    "def load_glove_model(File):\n",
    "    print(\"Loading Glove Model\")\n",
    "    glove_model = {}\n",
    "    with open(File,'r') as f:\n",
    "        for line in f:\n",
    "            split_line = line.split()\n",
    "            word = split_line[0]\n",
    "            embedding = np.array(split_line[1:], dtype=np.float64)\n",
    "            glove_model[word] = embedding\n",
    "    print(f\"{len(glove_model)} words loaded!\")\n",
    "    return glove_model\n",
    "\n",
    "glove_vectors = load_glove_model('pretrained/glove/glove.twitter.27B.200d.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sentence_embedding(sentence):\n",
    "    sentence_embedding = []\n",
    "    for word in simple_preprocess(sentence):\n",
    "        if word in glove_vectors:\n",
    "            sentence_embedding.append(glove_vectors[word])\n",
    "    if len(sentence_embedding) > 0:\n",
    "        return np.mean(sentence_embedding, axis=0)\n",
    "    else:\n",
    "        return np.zeros(200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load our data\n",
    "X_train, y_train, X_validate, y_validate, X_test, y_test = load_split_data()\n",
    "\n",
    "# Vectorize our sentences\n",
    "X_train = np.array([get_sentence_embedding(sentence) for sentence in X_train])\n",
    "X_validate = np.array([get_sentence_embedding(sentence) for sentence in X_validate])\n",
    "X_test = np.array([get_sentence_embedding(sentence) for sentence in X_test])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training...\n",
      "Training finished...\n",
      "Accuracy: 0.9043906698266184\n",
      "[[1 0]\n",
      " [1 0]\n",
      " [1 0]\n",
      " [1 0]\n",
      " [1 0]\n",
      " [1 0]\n",
      " [1 0]]\n"
     ]
    }
   ],
   "source": [
    "clf = DecisionTreeClassifier()\n",
    "\n",
    "# Train the classifier on the training data\n",
    "print(\"Training...\")\n",
    "clf.fit(X_train, y_train)\n",
    "print(\"Training finished...\")\n",
    "\n",
    "# Evaluate the accuracy of the classifier\n",
    "accuracy = clf.score(X_validate, y_validate)\n",
    "\n",
    "# Print the accuracy\n",
    "print(\"Accuracy:\", accuracy)\n",
    "\n",
    "print(clf.predict([get_sentence_embedding(s) for s in [\"You are shit\", \"You are in the shit\", \"You are an eye sore\", \"I don't like you\", \"I enjoy your company\", \"You are biatch\", \"You biiitch\"]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training...\n",
      "Training finished...\n",
      "Accuracy: 0.9409380067356866\n",
      "[[0 1]\n",
      " [1 0]\n",
      " [1 0]\n",
      " [0 1]\n",
      " [0 1]\n",
      " [0 1]\n",
      " [0 1]]\n"
     ]
    }
   ],
   "source": [
    "clf2 = RandomForestClassifier()\n",
    "\n",
    "# Train the classifier on the training data\n",
    "print(\"Training...\")\n",
    "clf2.fit(X_train, y_train)\n",
    "print(\"Training finished...\")\n",
    "\n",
    "# Evaluate the accuracy of the classifier\n",
    "accuracy = clf2.score(X_validate, y_validate)\n",
    "\n",
    "# Print the accuracy\n",
    "print(\"Accuracy:\", accuracy)\n",
    "\n",
    "print(clf2.predict([get_sentence_embedding(s) for s in [\"You are shit\", \"You are in the shit\", \"You are an eye sore\", \"I don't like you\", \"I enjoy your company\", \"You are biatch\", \"You biiitch\"]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(sentence, model):\n",
    "    return model.predict([get_sentence_embedding(sentence)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 0]])"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict(\"I am telling nothing to worry about. It is alright.\", clf2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = 'rdf_glovetwitt.sav'\n",
    "pickle.dump(clf2, open(filename, 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9339528501933392\n"
     ]
    }
   ],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
