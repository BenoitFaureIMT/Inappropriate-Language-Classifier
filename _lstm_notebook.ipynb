{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Machine Learning Project - Inappropriate Language Classification - LSTM\n",
    "\n",
    "This notebook is separate from the rest as the embedding layers are directly integrated in the model. That is because the model adds it's own embeddings for the count vectorizer. Furthermore, the LSTM model has a set input size, as such the inputs will be troncated from the ? end / start ?\n",
    "\n",
    "This Jupyter Notebook contains the following features:\n",
    "1. Model Choice\n",
    "    1. Using the Base Embedding Layer\n",
    "        - Data Tockenisation\n",
    "        - Model building with embedding layer\n",
    "    2. Using the GloVe embeddings\n",
    "        - Data Embedding\n",
    "        - Model building without embedding layer\n",
    "2. Model Training\n",
    "3. Model Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Parameters\n",
    "max_input_size = 200\n",
    "\n",
    "#Base LSTM\n",
    "embedding_dim = 200"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Model choice\n",
    "\n",
    "### 1. Default Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of known words:  72629\n"
     ]
    }
   ],
   "source": [
    "#Create Tockenizer\n",
    "max_words = 10000 # Max number of words to use in the tockenizer\n",
    "\n",
    "from experiment_baseplate import get_text_data\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "\n",
    "tokenizer = Tokenizer(num_words=max_words)\n",
    "tokenizer.fit_on_texts(get_text_data())\n",
    "word_index = tokenizer.word_index\n",
    "print(\"Number of known words: \", len(word_index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from experiment_baseplate import load_split_data\n",
    "\n",
    "X_train, y_train, X_validate, y_validate, X_test, y_test = load_split_data()\n",
    "\n",
    "#Tockenize data\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "X_train = tokenizer.texts_to_sequences(X_train)\n",
    "X_test = tokenizer.texts_to_sequences(X_test)\n",
    "X_validate = tokenizer.texts_to_sequences(X_validate)\n",
    "\n",
    "X_train = pad_sequences(X_train, maxlen=max_input_size)\n",
    "X_test = pad_sequences(X_test, maxlen=max_input_size)\n",
    "X_validate = pad_sequences(X_validate, maxlen=max_input_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define layers\n",
    "import tensorflow.keras.layers as tfl\n",
    "\n",
    "lstm_layers = [\n",
    "    tfl.Input(shape=(max_input_size,)),\n",
    "    tfl.Embedding(max_words, embedding_dim),\n",
    "    tfl.LSTM(64),\n",
    "    tfl.Dropout(0.2),\n",
    "    tfl.Dense(2, activation='softmax')\n",
    "]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GloVe Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "If needed download weights\n",
    "'''\n",
    "from experiment_baseplate import get_glove_model\n",
    "\n",
    "get_glove_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading GloVe model\n",
      "Done loading GloVe model\n",
      "\n",
      "Embedding data\n",
      "Done Embedding data\n"
     ]
    }
   ],
   "source": [
    "from experiment_baseplate import get_split_glove_embedding\n",
    "\n",
    "X_train, y_train, X_validate, y_validate, X_test, y_test = get_split_glove_embedding()\n",
    "\n",
    "# from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "# X_train = pad_sequences(X_train, maxlen=max_input_size)\n",
    "# X_test = pad_sequences(X_test, maxlen=max_input_size)\n",
    "# X_validate = pad_sequences(X_validate, maxlen=max_input_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "X_train = pad_sequences(X_train, maxlen=max_input_size)\n",
    "X_test = pad_sequences(X_test, maxlen=max_input_size)\n",
    "X_validate = pad_sequences(X_validate, maxlen=max_input_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(200,)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define layers\n",
    "import tensorflow.keras.layers as tfl\n",
    "\n",
    "lstm_layers = [\n",
    "    tfl.Input(shape=(max_input_size,)),\n",
    "    tfl.Embedding(max_words, embedding_dim),\n",
    "    tfl.LSTM(64),\n",
    "    tfl.Dropout(0.2),\n",
    "    tfl.Dense(2, activation='softmax')\n",
    "]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1 (InputLayer)        [(None, 200)]             0         \n",
      "                                                                 \n",
      " embedding (Embedding)       (None, 200, 200)          2000000   \n",
      "                                                                 \n",
      " lstm (LSTM)                 (None, 64)                67840     \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 64)                0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 2)                 130       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 2,067,970\n",
      "Trainable params: 2,067,970\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#Build the model\n",
    "from tensorflow.keras.models import Model\n",
    "\n",
    "if(len(lstm_layers) < 2):\n",
    "    print(\"Not enough layers in your model!\")\n",
    "    exit()\n",
    "\n",
    "for i in range(1, len(lstm_layers)):\n",
    "    lstm_layers[i] = lstm_layers[i](lstm_layers[i - 1])\n",
    "\n",
    "\n",
    "model = Model(inputs=lstm_layers[0], outputs=lstm_layers[-1])\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Model Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "3508/3508 [==============================] - 613s 174ms/step - loss: 0.2887 - accuracy: 0.8744 - val_loss: 0.2391 - val_accuracy: 0.8999\n",
      "Epoch 2/2\n",
      "3508/3508 [==============================] - 620s 177ms/step - loss: 0.1899 - accuracy: 0.9195 - val_loss: 0.2019 - val_accuracy: 0.9185\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1f8ca08eb80>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "epochs = 2\n",
    "batch_size = 32\n",
    "\n",
    "model.fit(X_train, y_train, epochs=epochs, batch_size=batch_size, validation_data=(X_validate, y_validate))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LSTM Model\n",
      "1003/1003 [==============================] - 41s 40ms/step\n",
      "Validate values -> accuracy : 0.9185480853186978 | precision : 0.9134559675550405 | recall : 0.8990021382751248\n",
      "502/502 [==============================] - 20s 40ms/step\n",
      "Test values -> accuracy : 0.9158662841461893 | precision : 0.9111918604651162 | recall : 0.8946767518196089\n"
     ]
    }
   ],
   "source": [
    "from experiment_baseplate import score\n",
    "\n",
    "print(\"LSTM Model\")\n",
    "print(\"Validate values -> \" + score( model.predict(X_validate) , y_validate))\n",
    "print(\"Test values -> \" + score( model.predict(X_test) , y_test))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bad_lang_class",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
