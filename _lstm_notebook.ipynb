{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Machine Learning Project - Inappropriate Language Classification - LSTM\n",
    "\n",
    "This notebook is separate from the rest as the embedding layers are directly integrated in the model. That is because the model adds it's own embeddings for the count vectorizer. Furthermore, the LSTM model has a set input size, as such the inputs will be troncated from the ? end / start ?\n",
    "\n",
    "This Jupyter Notebook contains the following features:\n",
    "1. Model Choice\n",
    "    1. Using the Base Embedding Layer\n",
    "        - Data Tockenisation\n",
    "        - Model building with embedding layer\n",
    "    2. Using the GloVe embeddings\n",
    "        - Data Embedding\n",
    "        - Model building without embedding layer\n",
    "2. Model Training\n",
    "3. Model Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Parameters\n",
    "max_input_size = 120"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Model choice"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Default Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create Tockenizer\n",
    "max_words = 10000 # Max number of words to use in the tockenizer\n",
    "\n",
    "from experiment_baseplate import get_text_data\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "\n",
    "tokenizer = Tokenizer(num_words=max_words)\n",
    "tokenizer.fit_on_texts(get_text_data())\n",
    "word_index = tokenizer.word_index\n",
    "print(\"Number of known words: \", len(word_index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from experiment_baseplate import load_split_data\n",
    "\n",
    "X_train, y_train, X_validate, y_validate, X_test, y_test = load_split_data()\n",
    "\n",
    "#Tockenize data\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "def post_process(X_values):\n",
    "    X_values = tokenizer.texts_to_sequences(X_values)\n",
    "    return pad_sequences(X_values, maxlen=max_input_size)\n",
    "\n",
    "X_train = post_process(X_train)\n",
    "X_test = post_process(X_test)\n",
    "X_validate = post_process(X_validate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define layers\n",
    "import tensorflow.keras.layers as tfl\n",
    "\n",
    "embedding_dim = 200\n",
    "\n",
    "lstm_layers = [\n",
    "    tfl.Input(shape=(max_input_size,)),\n",
    "    tfl.Embedding(max_words, embedding_dim),\n",
    "    tfl.LSTM(64),\n",
    "    tfl.Dropout(0.2),\n",
    "    tfl.Dense(2, activation='softmax')\n",
    "]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GloVe Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "If needed download weights\n",
    "'''\n",
    "from experiment_baseplate import get_glove_model\n",
    "\n",
    "get_glove_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from experiment_baseplate import get_split_glove_embedding\n",
    "\n",
    "X_train, y_train, X_validate, y_validate, X_test, y_test = get_split_glove_embedding()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "import numpy as np\n",
    "\n",
    "def post_process(X_values):\n",
    "    return np.array( pad_sequences(X_values, maxlen=max_input_size) )# , dtype=np.uint8)\n",
    "\n",
    "X_train = post_process(X_train)\n",
    "X_test = post_process(X_test)\n",
    "X_validate = post_process(X_validate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define layers\n",
    "import tensorflow.keras.layers as tfl\n",
    "\n",
    "glove_embedding_dim = X_train.shape[2]\n",
    "\n",
    "lstm_layers = [\n",
    "    tfl.Input(shape=(max_input_size, glove_embedding_dim)),\n",
    "    tfl.LSTM(64),\n",
    "    tfl.Dropout(0.2),\n",
    "    tfl.Dense(2, activation='softmax')\n",
    "]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Build the model\n",
    "from tensorflow.keras.models import Model\n",
    "\n",
    "if(len(lstm_layers) < 2):\n",
    "    print(\"Not enough layers in your model!\")\n",
    "    exit()\n",
    "\n",
    "for i in range(1, len(lstm_layers)):\n",
    "    lstm_layers[i] = lstm_layers[i](lstm_layers[i - 1])\n",
    "\n",
    "\n",
    "model = Model(inputs=lstm_layers[0], outputs=lstm_layers[-1])\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Train the model\n",
    "epochs = 10\n",
    "batch_size = 64\n",
    "\n",
    "model.fit(X_train, y_train, epochs=epochs, batch_size=batch_size, validation_data=(X_validate, y_validate))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from experiment_baseplate import score\n",
    "\n",
    "print(\"LSTM Model\")\n",
    "print(\"Validate values -> \" + score( model.predict(X_validate) , y_validate))\n",
    "print(\"Test values -> \" + score( model.predict(X_test) , y_test))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bad_lang_class",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
