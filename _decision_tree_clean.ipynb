{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Decision Tree Model\n",
    "\n",
    "Classification using a decision tree model. The model is sourced from the sklearn.tree module. There are two options for tockenisation and embedding:\n",
    "- **CountVectorizer** (tockenisation)\n",
    "- **GloVe model** (tockenisation + embedding)\n",
    "\n",
    "The **CountVectorizer** has it's dictionary created on the entire dataset, as such, it is limited to the words that are present in the dataset. This might contain words that haven't been seen by pretrained models. It is however entirely sure that pretrained models have seen certain words that aren't present in the dataset. Furethermore it doesn't embed the words, as such the models will need to infer their own relations between then words.\n",
    "\n",
    "The **GloVe model** is a pretrained model trained on a large corpus of words. It allows for both vectorization and embedding of the words. This allows for a first relation between different words to be created. For example, the embeddings of King - Man + Woman would equal Queen. Furthermore, it's dicitonary contains words that are not present in the dataset, this allows the entire trained model to be applied to be applied to new elements containing unseen words more effectively. For example, the word *biatch* not contained in the corpus would have it's embedding close to that of *bitch* which would allow the model to infer it's meaning.\n",
    "\n",
    "This Jupyter Notebook contains the following features:\n",
    "1. Dataset loading\n",
    "2. Tockenisation + Embedding\n",
    "- Using the CountVectorizer\n",
    "- Using the GloVe model\n",
    "3. Data preprocessing\n",
    "4. Training of the Decision Tree\n",
    "5. Testing and Evaluation of the Decision Tree\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Data Preparation\n",
    "\n",
    "Here we will load the data, choose a tockeniser and preprocess the data by tockenising it. **Choose only one of the tockenisers**, rerunning a block will overwrite the other.\n",
    "\n",
    "### Load Data - Count Vectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from experiment_baseplate import get_split_count_vectorizer\n",
    "\n",
    "X_train, y_train, X_validate, y_validate, X_test, y_test = get_split_count_vectorizer()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Data - GloVe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "If needed download weights\n",
    "'''\n",
    "from experiment_baseplate import get_glove_model\n",
    "\n",
    "get_glove_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading GloVe model\n",
      "Done loading GloVe model\n",
      "\n",
      "Embedding data\n",
      "Done Embedding data\n"
     ]
    }
   ],
   "source": [
    "from experiment_baseplate import get_split_glove_embedding\n",
    "\n",
    "X_train, y_train, X_validate, y_validate, X_test, y_test = get_split_glove_embedding()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Decision Tree Training\n",
    "\n",
    "Make sure you have imported the data, click on run, sit back and relax while the model trains."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training...\n",
      "Training finished...\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "clf = DecisionTreeClassifier()\n",
    "\n",
    "print(\"Training...\")\n",
    "clf.fit(X_train, y_train)\n",
    "print(\"Training finished...\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Decision Tree Testing\n",
    "\n",
    "Once you have trained, click on run and get the results on unseen data. You will have both test results on the validate and test. That is because the validation dataset wasn't used during training and it is bigger. The testing dataset is good to compare with the other models. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validate values -> accuracy : 0.9463639765498316 | precision : 0.9473760721035034 | recall : 0.9290092658588739\n",
      "Test values -> accuracy : 0.9433703380316827 | precision : 0.9443392102579047 | recall : 0.9249322106464963\n"
     ]
    }
   ],
   "source": [
    "from experiment_baseplate import score\n",
    "\n",
    "print(\"Validate values -> \" + score( clf.predict(X_validate) , y_validate))\n",
    "print(\"Test values -> \" + score( clf.predict(X_test) , y_test))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bad_lang_class",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
